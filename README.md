# ğŸ™ï¸ Whisper Transcription Module

## ğŸŒŸ Overview

A powerful, flexible Python module for audio transcription leveraging OpenAI's Whisper model, designed to transform audio content into accurate, multilingual text.

## âœ¨ Key Features

- ğŸ”Š **Advanced Audio Transcription**
  - Utilizes state-of-the-art Whisper AI technology
  - Supports multiple languages and dialects

- ğŸŒ **Multilingual Support**
  - Transcribe and translate audio across 99 languages
  - Automatic language detection

- ğŸ“„ **Flexible Output Formats**
  - TXT, JSON, SRT, VTT
  - Customizable transcription settings

- ğŸ“‚ **Versatile Processing**
  - Single file and batch processing
  - Configurable model sizes
  - GPU and CPU support

  
## ğŸ“š Documentation
| ğŸ‡ºğŸ‡¸ English| ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e |
|-------------------------------------------------|-------------|
| [Installation Guide](docs/en/README.md)| [Installation Guide](docs/en/README.md)|
| [CLI Usage Guide](docs/en/README.md)|[Komut SatÄ±rÄ± KullanÄ±m KÄ±lavuzu](docs/tr/README.md) |
| [Module Usage Guide](docs/en/MODULE_USAGE_EN.md)| [ModÃ¼l KullanÄ±m KÄ±lavuzu](docs/tr/MODULE_USAGE_TR.md) |
| [Feature Specifications](docs/en/FEATURES_EN.md)| [Ã–zellik SpesifikasyonlarÄ±](docs/tr/FEATURES_TR.md)|

## ğŸš€ Demo Scripts

The `demo_scripts` directory offers comprehensive scenarios demonstrating the module's capabilities:

| Scenario | Description | Key Features |
|----------|-------------|--------------|
| 1: Basic Transcription | Simple audio transcription | Default 'base' model, quick processing |
| 2: Multilingual Translation | Translate audio to English | Multi-language support, configurable logging |
| 3: Batch Processing | Process multiple audio files | Directory-wide transcription, format flexibility |
| 4: Advanced Configuration | Detailed transcription control | Quality filtering, segment management |
| 5: Error Handling | Robust error management | Fallback strategies, comprehensive logging |
| 6: Advanced Batch Processing | Large-scale transcription | Parallel processing, detailed reporting |

## ğŸ“‹ System Requirements

### ğŸ’» Computational Resources
- **Python**: 3.8+
- **CPU**: All models supported
- **GPU**: Optional acceleration
  - Use `--device cuda` for GPU transcription
  - Automatic CPU fallback

### ğŸ“¦ Dependencies
- openai-whisper
- torch
- numpy
- soundfile
- ffmpeg-python

## ğŸ¤ Contributing

1. Fork the repository
2. Create a virtual environment
3. Install development dependencies: `pip install -e .[dev]`
4. Run tests: `pytest`
5. Submit a pull request

## ğŸ› Support

- [Open an Issue](https://github.com/yourusername/WhisperDemo/issues)
- Consult [Troubleshooting Guide](docs/en/TROUBLESHOOTING.md)

## ğŸ“„ License

MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgements

- OpenAI for the Whisper model
- Python open-source community
